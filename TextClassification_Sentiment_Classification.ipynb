{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification_Sentiment_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6R3OJCW025ccnEnEJ/z8Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khamoh/NaturalLangProcessing/blob/master/TextClassification_Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvplBk4XrB0G",
        "colab_type": "text"
      },
      "source": [
        "# Vectorization \n",
        "**bold text**\n",
        "\n",
        "1) Frequency based vectorization \n",
        "  - Set of mathematical methods \n",
        "\n",
        "  Three techniques \n",
        "  *   Count vectorization - Fastest method, lease accurate \n",
        "  *   TFIDF - Term Freq (times word has appeared in document) and Inverse \n",
        "              document frequency (how many documents it has appreared) \n",
        "              - Slower better accuracy \n",
        "\n",
        "              w(ij) = tf(ij)  x log (N/df(i))\n",
        "  *   Co occurrence vectorization   - Slowest - most acurate - computationally \n",
        "                    very expensive. Prediciton based methods are better and  \n",
        "                    less expensive \n",
        "  \n",
        "\n",
        "2) Prediction based vectorisation \n",
        "  - Neural network based methods \n",
        "  \n",
        "\n",
        "  *   Stanford - Glove \n",
        "  *   Facebook - fast text \n",
        "  *   Google  - word2rec  \n",
        "  *   Google  - elmo \n",
        "  *   Google  - BERT  \n",
        "\n",
        "fasttext.cc \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvyLQMr3y_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [(\"Pizza is great and I love pizza.\",\"Positive\"),\n",
        "(\"I hate burger and its bad to eat burger.\",\"Negative\"),\n",
        "(\"I hate dirty tables.\",\"Negative\"),\n",
        "(\"Burger is amazing and I love it more than anything\",\"Positive\"),\n",
        "(\"My boss is a monster and I hate him\",\"Negative\"),\n",
        "(\"The food was delivered late and I hate late delivery\",\"Negative\"),\n",
        "(\"My wife love pizza and burger more than me\",\"Positive\"),\n",
        "(\"the table was bad and dirty and i hate this\",\"Negative\"),\n",
        "(\"Food was delicious and I love it\",\"Positive\"),\n",
        "(\"It great to have good food at good time\",\"Positive\"),\n",
        "(\"icecream was not good.\",'Negative'),\n",
        "(\"icecream was not bad.\",'Positive'),\n",
        "(\"Pizza was not bad.\",'Positive'),\n",
        "(\"Burger was bad.\",'Negative'),\n",
        "(\"juice was not good.\",'Negative'),\n",
        "(\"juice was good.\",'Positive'),\n",
        "(\"ketchup was bad.\",'Negative'),\n",
        "(\"ketchup was good.\",'Positive'),]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_cMAEO4h8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "74f206d6-c391-4f0a-d1b3-2f3a777ecb43"
      },
      "source": [
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pizza is great and I love pizza.', 'Positive'),\n",
              " ('I hate burger and its bad to eat burger.', 'Negative'),\n",
              " ('I hate dirty tables.', 'Negative'),\n",
              " ('Burger is amazing and I love it more than anything', 'Positive'),\n",
              " ('My boss is a monster and I hate him', 'Negative'),\n",
              " ('The food was delivered late and I hate late delivery', 'Negative'),\n",
              " ('My wife love pizza and burger more than me', 'Positive'),\n",
              " ('the table was bad and dirty and i hate this', 'Negative'),\n",
              " ('Food was delicious and I love it', 'Positive'),\n",
              " ('It great to have good food at good time', 'Positive'),\n",
              " ('icecream was not good.', 'Negative'),\n",
              " ('icecream was not bad.', 'Positive'),\n",
              " ('Pizza was not bad.', 'Positive'),\n",
              " ('Burger was bad.', 'Negative'),\n",
              " ('juice was not good.', 'Negative'),\n",
              " ('juice was good.', 'Positive'),\n",
              " ('ketchup was bad.', 'Negative'),\n",
              " ('ketchup was good.', 'Positive')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ11NQ504kXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for doc in data: \n",
        "  x.append(doc[0])\n",
        "  y.append(doc[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnHnCArH47Ns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "8f366fca-8329-491c-b940-d6105a26aa8f"
      },
      "source": [
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Positive',\n",
              " 'Negative',\n",
              " 'Negative',\n",
              " 'Positive',\n",
              " 'Negative',\n",
              " 'Negative',\n",
              " 'Positive',\n",
              " 'Negative',\n",
              " 'Positive',\n",
              " 'Positive',\n",
              " 'Negative',\n",
              " 'Positive',\n",
              " 'Positive',\n",
              " 'Negative',\n",
              " 'Negative',\n",
              " 'Positive',\n",
              " 'Negative',\n",
              " 'Positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6453Agiu4_Od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "aa3241bf-ee2c-44a0-b99e-583eb60c0096"
      },
      "source": [
        "#count vectorisation \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "cvec = CountVectorizer(lowercase=True, stop_words = 'english' )\n",
        "\n",
        "#train the CountVectorizer Object \n",
        "cvec.fit(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNICgXYG53ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9034f6e5-82b7-408f-e02d-f684252da86c"
      },
      "source": [
        "print(cvec.get_feature_names())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['amazing', 'bad', 'boss', 'burger', 'delicious', 'delivered', 'delivery', 'dirty', 'eat', 'food', 'good', 'great', 'hate', 'icecream', 'juice', 'ketchup', 'late', 'love', 'monster', 'pizza', 'table', 'tables', 'time', 'wife']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcCiE6ns6nZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "776a15a7-72ce-4dfb-8c3c-83d70f967752"
      },
      "source": [
        "print(len(cvec.get_feature_names()))\n",
        "#size = 24 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32LU67nQ5-eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemming can be done to convert the words to its base form... like delivered and delivery is the same base work \n",
        "#Process of vectorisation "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q__NXvzo6r-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97321e02-cb7c-43fe-cbf6-74b6b3a253ec"
      },
      "source": [
        "x2 = cvec.transform(x).toarray()\n",
        "x2.shape\n",
        "# 18 rows of data and 24 unique feature words "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efnnakZv7LV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "aad16f23-b0c4-4495-9a14-04e1f9ab8dc8"
      },
      "source": [
        "x2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0],\n",
              "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ1dcD2P7OYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "93cf69d5-8dc9-4e0b-ce6e-7d7699327d91"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier (hidden_layer_sizes = (100,50), max_iter = 500, activation= 'relu')\n",
        "\n",
        "# train the model \n",
        "\n",
        "model.fit(x2,y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwIzl0gf7sAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a98ec4a4-5ad1-44cf-e3bc-13f199bec141"
      },
      "source": [
        "model.predict(cvec.transform(['I hate burger']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Negative'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Pv4Zcr8JE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c0d9b2a-43b3-4159-e7e4-93c2eb591651"
      },
      "source": [
        "model.predict(cvec.transform(['I love burger']))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zJsxDqb8rBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28dcb90c-3db9-4eed-abe0-f9ee24957f0a"
      },
      "source": [
        "model.predict(cvec.transform(['i love pizza and burger']))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq6Hu1OW8v7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c293768-03a2-4ec8-beb7-32e90002f788"
      },
      "source": [
        "model.predict(cvec.transform(['dosa is not bad']))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjPGPagf9MbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOT stopword is removed from stopword from dictionary  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pea-ggpD9XG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "stop_words = list(ENGLISH_STOP_WORDS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZwO0fqP9duE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words.remove(\"not\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjSzdSM19iQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "32be5887-dc1c-426e-a120-61ea9c30254e"
      },
      "source": [
        "# Count Vectorizaton\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cvec = CountVectorizer(lowercase=True,stop_words=stop_words)\n",
        "# train the countvectorizer object\n",
        "cvec.fit(x)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None,\n",
              "                stop_words=['should', 'seemed', 'wherein', 'been', 'between',\n",
              "                            'has', 'he', 'these', 'seem', 'again', 'ten',\n",
              "                            'under', 'until', 'would', 'behind', 'every',\n",
              "                            'anything', 'hasnt', 'less', 'neither', 'few',\n",
              "                            'five', 'hereby', 'due', 'former', 'hereupon',\n",
              "                            'more', 'also', 'mostly', 'formerly', ...],\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOqFYocG-CIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "0a4cc038-63f8-41fa-f31a-1e6e1ceeadda"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier (hidden_layer_sizes = (100,50), max_iter = 500, activation= 'relu')\n",
        "\n",
        "# train the model \n",
        "\n",
        "model.fit(x2,y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RdKOEBS-Wrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "05beae12-6af0-4570-93cb-e19fde9e9666"
      },
      "source": [
        "print(cvec.get_feature_names())\n",
        "print(len(cvec.get_feature_names()))\n",
        "x2 = cvec.transform(x).toarray()\n",
        "x2.shape\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['amazing', 'bad', 'boss', 'burger', 'delicious', 'delivered', 'delivery', 'dirty', 'eat', 'food', 'good', 'great', 'hate', 'icecream', 'juice', 'ketchup', 'late', 'love', 'monster', 'not', 'pizza', 'table', 'tables', 'time', 'wife']\n",
            "25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m8s7bUB-dm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "ff447f64-3d68-45c1-86e9-86cb348ab5fc"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,50),max_iter=500,activation='relu')\n",
        "\n",
        "#train the model\n",
        "model.fit(x2,y)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwBRQEvM9lvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2744a5f7-2108-4842-e4b2-37b9581e8fc4"
      },
      "source": [
        "model.predict(cvec.transform(['dosa is not bad']))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtzF75Zb_UIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unigram u =1  ; i, love, python  all words as features \n",
        "# Unigram u =2  ; i, love, python  , i love, love python   1, 2 combination of words as features \n",
        "# Unigram u =3  ; i, love, python  , i love, love python   , i love python   1,2, 3 combination of words as features "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL37BmKX_3or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count Vectorizaton\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cvec = CountVectorizer(lowercase=True,stop_words=stop_words,ngram_range=(1,2),min_df = 2) # ngram_range is for unigram or bigram (1,2) or trigram (1,2,3) , mid_df =2 => no of times this has occured in document frequecy \n",
        "# train the countvectorizer object\n",
        "cvec.fit(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}